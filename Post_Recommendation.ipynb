{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "class RecommendationSystem:\n",
        "    def __init__(self):\n",
        "        self.user_features = None\n",
        "        self.post_features = None\n",
        "        self.user_encoder = LabelEncoder()\n",
        "        self.post_encoder = LabelEncoder()\n",
        "        self.tfidf_vectorizer = TfidfVectorizer(max_features=20, stop_words='english')\n",
        "        self.scaler = StandardScaler()\n",
        "\n",
        "    def load_and_split_data(self, users_df, posts_df, engagements_df, test_size=0.2):\n",
        "        self.users_df = users_df.copy()\n",
        "        self.posts_df = posts_df.copy()\n",
        "        self.engagements_df = engagements_df.copy()\n",
        "\n",
        "        print(\"Dataset shapes:\")\n",
        "        print(f\"Users: {self.users_df.shape}\")\n",
        "        print(f\"Posts: {self.posts_df.shape}\")\n",
        "        print(f\"Engagements: {self.engagements_df.shape}\")\n",
        "\n",
        "        # Split engagements into train and test\n",
        "        self.engagements_train, self.engagements_test = train_test_split(\n",
        "            self.engagements_df, test_size=test_size, random_state=42, stratify=self.engagements_df['user_id']\n",
        "        )\n",
        "\n",
        "        print(f\"Training engagements: {len(self.engagements_train)}\")\n",
        "        print(f\"Test engagements: {len(self.engagements_test)}\")\n",
        "\n",
        "        # Preprocess data using only training engagements\n",
        "        self._preprocess_users()\n",
        "        self._preprocess_posts()\n",
        "        self._preprocess_engagements()\n",
        "\n",
        "    def _preprocess_users(self):\n",
        "\n",
        "        # Handle missing values\n",
        "        self.users_df['top_3_interests'] = self.users_df['top_3_interests'].fillna('')\n",
        "        self.users_df['age'] = self.users_df['age'].fillna(self.users_df['age'].median())\n",
        "        self.users_df['gender'] = self.users_df['gender'].fillna('unknown')\n",
        "        self.users_df['past_engagement_score'] = self.users_df['past_engagement_score'].fillna(0)\n",
        "\n",
        "        # Convert top_3_interests to list\n",
        "        self.users_df['interests_list'] = self.users_df['top_3_interests'].apply(\n",
        "            lambda x: [interest.strip().lower() for interest in str(x).split(',')] if x else []\n",
        "        )\n",
        "\n",
        "        # Get all unique interests\n",
        "        all_interests = set()\n",
        "        for interests in self.users_df['interests_list']:\n",
        "            all_interests.update(interests)\n",
        "        all_interests = sorted(list(all_interests))\n",
        "\n",
        "        print(f\"Found {len(all_interests)} unique interests: {all_interests}\")\n",
        "\n",
        "        # Create interest features\n",
        "        for interest in all_interests:\n",
        "            self.users_df[f'interest_{interest}'] = self.users_df['interests_list'].apply(\n",
        "                lambda x: 1 if interest in x else 0\n",
        "            )\n",
        "\n",
        "        # Encode gender\n",
        "        self.users_df['gender_encoded'] = LabelEncoder().fit_transform(self.users_df['gender'])\n",
        "\n",
        "        # Normalize numerical features\n",
        "        self.users_df['age_normalized'] = self.scaler.fit_transform(self.users_df[['age']])\n",
        "        self.users_df['engagement_score_normalized'] = self.scaler.fit_transform(\n",
        "            self.users_df[['past_engagement_score']]\n",
        "        )\n",
        "\n",
        "    def _preprocess_posts(self):\n",
        "\n",
        "        # Handle missing values\n",
        "        self.posts_df['tags'] = self.posts_df['tags'].fillna('')\n",
        "        self.posts_df['content_type'] = self.posts_df['content_type'].fillna('unknown')\n",
        "\n",
        "        # Process tags\n",
        "        self.posts_df['tags_list'] = self.posts_df['tags'].apply(\n",
        "            lambda x: [tag.strip().lower() for tag in str(x).split(',')] if x else []\n",
        "        )\n",
        "\n",
        "        # Create tag features using TF-IDF\n",
        "        all_tags = [' '.join(tags) for tags in self.posts_df['tags_list']]\n",
        "        if all_tags:\n",
        "            tag_features = self.tfidf_vectorizer.fit_transform(all_tags).toarray()\n",
        "            tag_feature_names = [f'tag_{i}' for i in range(tag_features.shape[1])]\n",
        "            tag_df = pd.DataFrame(tag_features, columns=tag_feature_names, index=self.posts_df.index)\n",
        "            self.posts_df = pd.concat([self.posts_df, tag_df], axis=1)\n",
        "\n",
        "        # Encode content_type\n",
        "        self.posts_df['content_type_encoded'] = LabelEncoder().fit_transform(\n",
        "            self.posts_df['content_type']\n",
        "        )\n",
        "\n",
        "    def _preprocess_engagements(self):\n",
        "\n",
        "        # Encode user_id and post_id\n",
        "        self.engagements_train['user_id_encoded'] = self.user_encoder.fit_transform(\n",
        "            self.engagements_train['user_id']\n",
        "        )\n",
        "        self.engagements_train['post_id_encoded'] = self.post_encoder.fit_transform(\n",
        "            self.engagements_train['post_id']\n",
        "        )\n",
        "\n",
        "        # Also encode test data using the same encoders\n",
        "        self.engagements_test['user_id_encoded'] = self.user_encoder.transform(\n",
        "            self.engagements_test['user_id']\n",
        "        )\n",
        "        self.engagements_test['post_id_encoded'] = self.post_encoder.transform(\n",
        "            self.engagements_test['post_id']\n",
        "        )\n",
        "\n",
        "        # Create engagement matrix from training data only\n",
        "        self.engagement_matrix = self.engagements_train.pivot(\n",
        "            index='user_id_encoded',\n",
        "            columns='post_id_encoded',\n",
        "            values='engagement'\n",
        "        ).fillna(0)\n",
        "\n",
        "        # Convert to binary (any engagement > 0 means user engaged with post)\n",
        "        self.engagement_matrix = (self.engagement_matrix > 0).astype(int)\n",
        "\n",
        "        print(f\"Engagement matrix shape: {self.engagement_matrix.shape}\")\n",
        "        print(f\"Total training engagements: {self.engagement_matrix.sum().sum()}\")\n",
        "\n",
        "    def create_features(self):\n",
        "\n",
        "        # User features: demographics + interests\n",
        "        interest_cols = [col for col in self.users_df.columns if col.startswith('interest_')]\n",
        "        user_demo_features = ['age_normalized', 'gender_encoded', 'engagement_score_normalized']\n",
        "\n",
        "        user_interest_features = self.users_df[interest_cols].values if interest_cols else np.zeros((len(self.users_df), 1))\n",
        "        user_demo_features = self.users_df[user_demo_features].values\n",
        "\n",
        "        self.user_features = np.hstack([user_demo_features, user_interest_features])\n",
        "\n",
        "        # Post features: content type + tags\n",
        "        tag_cols = [col for col in self.posts_df.columns if col.startswith('tag_')]\n",
        "        post_content_features = self.posts_df[['content_type_encoded']].values\n",
        "        post_tag_features = self.posts_df[tag_cols].values if tag_cols else np.zeros((len(self.posts_df), 1))\n",
        "\n",
        "        self.post_features = np.hstack([post_content_features, post_tag_features])\n",
        "\n",
        "        print(f\"User features shape: {self.user_features.shape}\")\n",
        "        print(f\"Post features shape: {self.post_features.shape}\")\n",
        "\n",
        "    def collaborative_filtering(self, user_id, top_k=3, n_factors=10):\n",
        "        try:\n",
        "            user_idx = self.user_encoder.transform([user_id])[0]\n",
        "\n",
        "            # Perform SVD on the engagement matrix\n",
        "            svd = TruncatedSVD(n_components=n_factors, random_state=42)\n",
        "            user_factors = svd.fit_transform(self.engagement_matrix)\n",
        "            item_factors = svd.components_.T\n",
        "\n",
        "            # Reconstruct the matrix\n",
        "            predicted_scores = user_factors @ item_factors.T\n",
        "\n",
        "            # Get predictions for this user\n",
        "            user_predictions = predicted_scores[user_idx]\n",
        "\n",
        "            # Get posts user has already engaged with in TRAINING data\n",
        "            user_engaged_train = set(self.engagements_train[\n",
        "                self.engagements_train['user_id'] == user_id\n",
        "            ]['post_id'])\n",
        "            engaged_indices = [self.post_encoder.transform([pid])[0] for pid in user_engaged_train\n",
        "                             if pid in self.post_encoder.classes_]\n",
        "\n",
        "            # Set already engaged posts to -inf\n",
        "            user_predictions[engaged_indices] = -np.inf\n",
        "\n",
        "            # Get top recommendations\n",
        "            valid_indices = np.where(user_predictions > -np.inf)[0]\n",
        "            if len(valid_indices) == 0:\n",
        "                return self._get_popular_posts(user_engaged_train, top_k), np.zeros(top_k)\n",
        "\n",
        "            top_indices = np.argsort(user_predictions)[::-1][:top_k]\n",
        "            recommended_posts = self.post_encoder.inverse_transform(top_indices)\n",
        "\n",
        "            return recommended_posts, user_predictions[top_indices]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in collaborative filtering for user {user_id}: {e}\")\n",
        "            user_engaged_train = set(self.engagements_train[\n",
        "                self.engagements_train['user_id'] == user_id\n",
        "            ]['post_id'])\n",
        "            return self._get_popular_posts(user_engaged_train, top_k), np.zeros(top_k)\n",
        "\n",
        "    def content_based_recommendation(self, user_id, top_k=3):\n",
        "        try:\n",
        "            user_idx = self.user_encoder.transform([user_id])[0]\n",
        "            user_row = self.users_df[self.users_df['user_id'] == user_id].iloc[0]\n",
        "            user_interests = user_row['interests_list']\n",
        "\n",
        "            if not user_interests:\n",
        "                user_engaged_train = set(self.engagements_train[\n",
        "                    self.engagements_train['user_id'] == user_id\n",
        "                ]['post_id'])\n",
        "                return self._get_popular_posts(user_engaged_train, top_k), np.zeros(top_k)\n",
        "\n",
        "            # Calculate similarity scores for all posts\n",
        "            scores = []\n",
        "            for post_idx, post_row in self.posts_df.iterrows():\n",
        "                post_id = post_row['post_id']\n",
        "                post_tags = post_row['tags_list']\n",
        "\n",
        "                # Calculate interest overlap\n",
        "                overlap = len(set(user_interests) & set(post_tags))\n",
        "                score = overlap / max(len(user_interests), 1)\n",
        "\n",
        "                # Add content type preference boost\n",
        "                if post_row['content_type'] in ['video', 'image']:\n",
        "                    score *= 1.1\n",
        "\n",
        "                scores.append((post_id, score))\n",
        "\n",
        "            # Sort by score\n",
        "            scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            # Filter out posts user already engaged with in training\n",
        "            user_engaged_train = set(self.engagements_train[\n",
        "                self.engagements_train['user_id'] == user_id\n",
        "            ]['post_id'])\n",
        "\n",
        "            recommendations = []\n",
        "            final_scores = []\n",
        "            for post_id, score in scores:\n",
        "                if post_id not in user_engaged_train and len(recommendations) < top_k:\n",
        "                    recommendations.append(post_id)\n",
        "                    final_scores.append(score)\n",
        "\n",
        "            # If not enough recommendations, add popular ones\n",
        "            if len(recommendations) < top_k:\n",
        "                additional = self._get_popular_posts(\n",
        "                    user_engaged_train.union(set(recommendations)),\n",
        "                    top_k - len(recommendations)\n",
        "                )\n",
        "                recommendations.extend(additional)\n",
        "                final_scores.extend([0.1] * len(additional))\n",
        "\n",
        "            return np.array(recommendations), np.array(final_scores)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in content-based recommendation for user {user_id}: {e}\")\n",
        "            user_engaged_train = set(self.engagements_train[\n",
        "                self.engagements_train['user_id'] == user_id\n",
        "            ]['post_id'])\n",
        "            return self._get_popular_posts(user_engaged_train, top_k), np.zeros(top_k)\n",
        "\n",
        "    def _get_popular_posts(self, exclude_posts, top_k):\n",
        "        post_engagement_counts = self.engagements_train.groupby('post_id').size()\n",
        "        popular_posts = post_engagement_counts.sort_values(ascending=False).index.tolist()\n",
        "\n",
        "        recommendations = []\n",
        "        for post in popular_posts:\n",
        "            if post not in exclude_posts and len(recommendations) < top_k:\n",
        "                recommendations.append(post)\n",
        "\n",
        "        # If still not enough, use any posts\n",
        "        if len(recommendations) < top_k:\n",
        "            all_posts = set(self.posts_df['post_id'])\n",
        "            remaining_posts = list(all_posts - exclude_posts - set(recommendations))\n",
        "            if remaining_posts:\n",
        "                additional = np.random.choice(remaining_posts,\n",
        "                                           size=min(top_k - len(recommendations), len(remaining_posts)),\n",
        "                                           replace=False)\n",
        "                recommendations.extend(additional)\n",
        "\n",
        "        return recommendations\n",
        "\n",
        "    def hybrid_recommendation(self, user_id, top_k=3):\n",
        "        # Get recommendations from both methods\n",
        "        content_recs, content_scores = self.content_based_recommendation(user_id, top_k * 2)\n",
        "        collab_recs, collab_scores = self.collaborative_filtering(user_id, top_k * 2)\n",
        "\n",
        "        # Normalize scores\n",
        "        if len(content_scores) > 0 and np.max(content_scores) > 0:\n",
        "            content_scores = content_scores / np.max(content_scores)\n",
        "        if len(collab_scores) > 0 and np.max(collab_scores) > 0:\n",
        "            collab_scores = collab_scores / np.max(collab_scores)\n",
        "\n",
        "        # Combine recommendations\n",
        "        combined_scores = {}\n",
        "\n",
        "        # Add content-based scores (weight: 0.6)\n",
        "        for post, score in zip(content_recs, content_scores):\n",
        "            combined_scores[post] = score * 0.6\n",
        "\n",
        "        # Add collaborative scores (weight: 0.4)\n",
        "        for post, score in zip(collab_recs, collab_scores):\n",
        "            if post in combined_scores:\n",
        "                combined_scores[post] += score * 0.4\n",
        "            else:\n",
        "                combined_scores[post] = score * 0.4\n",
        "\n",
        "        # Sort by combined score and get top K\n",
        "        sorted_posts = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "        final_recommendations = [post for post, score in sorted_posts[:top_k]]\n",
        "        final_scores = [score for post, score in sorted_posts[:top_k]]\n",
        "\n",
        "        return np.array(final_recommendations), np.array(final_scores)\n",
        "\n",
        "    def generate_recommendations(self):\n",
        "\n",
        "        recommendations = {}\n",
        "\n",
        "        for user_id in self.users_df['user_id']:\n",
        "            rec_posts, scores = self.hybrid_recommendation(user_id)\n",
        "            recommendations[user_id] = {\n",
        "                'recommended_posts': rec_posts,\n",
        "                'scores': scores\n",
        "            }\n",
        "\n",
        "        return recommendations\n",
        "\n",
        "    def save_recommendations_to_csv(self, recommendations, filename='recommendations.csv'):\n",
        "        print(f\"\\nSaving recommendations to {filename}...\")\n",
        "\n",
        "        # Create a list to store the recommendation data\n",
        "        recommendation_data = []\n",
        "\n",
        "        for user_id, rec_data in recommendations.items():\n",
        "            recommended_posts = rec_data['recommended_posts']\n",
        "            scores = rec_data['scores']\n",
        "\n",
        "            # Create a row for this user\n",
        "            row = {\n",
        "                'user_id': user_id,\n",
        "                'recommended_post_1': recommended_posts[0] if len(recommended_posts) > 0 else None,\n",
        "                'recommended_post_2': recommended_posts[1] if len(recommended_posts) > 1 else None,\n",
        "                'recommended_post_3': recommended_posts[2] if len(recommended_posts) > 2 else None,\n",
        "                'score_1': scores[0] if len(scores) > 0 else 0,\n",
        "                'score_2': scores[1] if len(scores) > 1 else 0,\n",
        "                'score_3': scores[2] if len(scores) > 2 else 0\n",
        "            }\n",
        "            recommendation_data.append(row)\n",
        "\n",
        "        # Create DataFrame and save to CSV\n",
        "        recommendations_df = pd.DataFrame(recommendation_data)\n",
        "        recommendations_df.to_csv(filename, index=False)\n",
        "\n",
        "        print(f\"Successfully saved {len(recommendations_df)} user recommendations to {filename}\")\n",
        "\n",
        "        self.save_detailed_recommendations(recommendations, filename='detailed_recommendations.csv')\n",
        "\n",
        "        return recommendations_df\n",
        "\n",
        "    def save_detailed_recommendations(self, recommendations, filename='detailed_recommendations.csv'):\n",
        "        detailed_data = []\n",
        "\n",
        "        for user_id, rec_data in recommendations.items():\n",
        "            user_info = self.users_df[self.users_df['user_id'] == user_id].iloc[0]\n",
        "            recommended_posts = rec_data['recommended_posts']\n",
        "            scores = rec_data['scores']\n",
        "\n",
        "            for i, (post_id, score) in enumerate(zip(recommended_posts, scores)):\n",
        "                post_info = self.posts_df[self.posts_df['post_id'] == post_id].iloc[0]\n",
        "\n",
        "                row = {\n",
        "                    'user_id': user_id,\n",
        "                    'user_interests': user_info['top_3_interests'],\n",
        "                    'recommendation_rank': i + 1,\n",
        "                    'post_id': post_id,\n",
        "                    'post_content_type': post_info['content_type'],\n",
        "                    'post_tags': post_info['tags'],\n",
        "                    'recommendation_score': score,\n",
        "                    'match_reason': self._get_match_reason(user_info, post_info)\n",
        "                }\n",
        "                detailed_data.append(row)\n",
        "\n",
        "        detailed_df = pd.DataFrame(detailed_data)\n",
        "        detailed_df.to_csv(filename, index=False)\n",
        "        print(f\"Successfully saved detailed recommendations to {filename}\")\n",
        "\n",
        "        return detailed_df\n",
        "\n",
        "    def _get_match_reason(self, user_info, post_info):\n",
        "        user_interests = user_info['interests_list']\n",
        "        post_tags = post_info['tags_list']\n",
        "\n",
        "        common_interests = set(user_interests) & set(post_tags)\n",
        "        if common_interests:\n",
        "            return f\"Common interests: {', '.join(common_interests)}\"\n",
        "        else:\n",
        "            return \"Popular content or collaborative filtering\"\n",
        "\n",
        "    def evaluate_recommendations(self, recommendations, k=3):\n",
        "\n",
        "        hits = 0\n",
        "        total_recommendations = 0\n",
        "        user_coverage = 0\n",
        "\n",
        "        for user_id, rec_data in recommendations.items():\n",
        "            recommended_posts = rec_data['recommended_posts'][:k]\n",
        "\n",
        "            user_test_engagements = set(self.engagements_test[\n",
        "                self.engagements_test['user_id'] == user_id\n",
        "            ]['post_id'])\n",
        "\n",
        "            user_hits = 0\n",
        "            for post in recommended_posts:\n",
        "                if post in user_test_engagements:\n",
        "                    hits += 1\n",
        "                    user_hits += 1\n",
        "                total_recommendations += 1\n",
        "\n",
        "            if user_hits > 0:\n",
        "                user_coverage += 1\n",
        "\n",
        "        precision = hits / total_recommendations if total_recommendations > 0 else 0\n",
        "        coverage = user_coverage / len(self.users_df) if len(self.users_df) > 0 else 0\n",
        "\n",
        "        print(f\"Precision@{k}: {precision:.4f}\")\n",
        "        print(f\"User Coverage@{k}: {coverage:.4f}\")\n",
        "        print(f\"Total Recommendations: {total_recommendations}\")\n",
        "        print(f\"Total Hits: {hits}\")\n",
        "        print(f\"Users with at least one hit: {user_coverage}/{len(self.users_df)}\")\n",
        "\n",
        "        return precision, coverage\n",
        "\n",
        "def main():\n",
        "    users_df = pd.read_csv('Users.csv')\n",
        "    posts_df = pd.read_csv('Posts.csv')\n",
        "    engagements_df = pd.read_csv('Engagements.csv')\n",
        "\n",
        "    rec_system = RecommendationSystem()\n",
        "    rec_system.load_and_split_data(users_df, posts_df, engagements_df, test_size=0.2)\n",
        "    rec_system.create_features()\n",
        "\n",
        "    recommendations = rec_system.generate_recommendations()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"DETAILED RECOMMENDATIONS (First 10 Users)\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for i, (user_id, rec_data) in enumerate(list(recommendations.items())[:10]):\n",
        "        user_info = users_df[users_df['user_id'] == user_id].iloc[0]\n",
        "        print(f\"\\nUser {user_id} (Interests: {user_info['top_3_interests']}):\")\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        user_test_engagements = set(rec_system.engagements_test[\n",
        "            rec_system.engagements_test['user_id'] == user_id\n",
        "        ]['post_id'])\n",
        "\n",
        "        print(f\"Test engagements to predict: {len(user_test_engagements)} posts\")\n",
        "\n",
        "        for j, (post_id, score) in enumerate(zip(rec_data['recommended_posts'], rec_data['scores'])):\n",
        "            post_info = posts_df[posts_df['post_id'] == post_id].iloc[0]\n",
        "            is_hit = \"✓ HIT!\" if post_id in user_test_engagements else \" \"\n",
        "\n",
        "            print(f\"  {is_hit} {j+1}. Post {post_id} (Score: {score:.3f})\")\n",
        "            print(f\"     Type: {post_info['content_type']}, Tags: {post_info['tags']}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"EVALUATION RESULTS (TEST DATA)\")\n",
        "    print(\"=\" * 60)\n",
        "    precision, coverage = rec_system.evaluate_recommendations(recommendations)\n",
        "\n",
        "    # Save recommendations to CSV\n",
        "    recommendations_df = rec_system.save_recommendations_to_csv(recommendations)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"METHOD COMPARISON\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    methods = [\n",
        "        ('Content-Based', rec_system.content_based_recommendation),\n",
        "        ('Collaborative', rec_system.collaborative_filtering),\n",
        "        ('Hybrid', rec_system.hybrid_recommendation)\n",
        "    ]\n",
        "\n",
        "    for method_name, method_func in methods:\n",
        "        method_recs = {}\n",
        "        for user_id in rec_system.users_df['user_id']:\n",
        "            rec_posts, scores = method_func(user_id)\n",
        "            method_recs[user_id] = {'recommended_posts': rec_posts, 'scores': scores}\n",
        "\n",
        "        precision, coverage = rec_system.evaluate_recommendations(method_recs)\n",
        "        print(f\"{method_name:20} Precision@3: {precision:.4f}, Coverage: {coverage:.4f}\")\n",
        "\n",
        "    return rec_system, recommendations, recommendations_df\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    rec_system, recommendations, recommendations_df = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GD2OE8ZorMNJ",
        "outputId": "c8357870-1e09-4981-f44f-3688dd2d28ef"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shapes:\n",
            "Users: (50, 5)\n",
            "Posts: (100, 4)\n",
            "Engagements: (1000, 3)\n",
            "Training engagements: 800\n",
            "Test engagements: 200\n",
            "Found 10 unique interests: ['art', 'fashion', 'fitness', 'food', 'gaming', 'literature', 'music', 'sports', 'tech', 'travel']\n",
            "Engagement matrix shape: (50, 100)\n",
            "Total training engagements: 392\n",
            "User features shape: (50, 13)\n",
            "Post features shape: (100, 11)\n",
            "\n",
            "============================================================\n",
            "DETAILED RECOMMENDATIONS (First 10 Users)\n",
            "============================================================\n",
            "\n",
            "User U1 (Interests: sports, art, gaming):\n",
            "--------------------------------------------------\n",
            "Test engagements to predict: 4 posts\n",
            "    1. Post P78 (Score: 0.600)\n",
            "     Type: video, Tags: sports, art\n",
            "    2. Post P22 (Score: 0.545)\n",
            "     Type: audio, Tags: sports, art\n",
            "    3. Post P12 (Score: 0.400)\n",
            "     Type: video, Tags: fitness\n",
            "\n",
            "User U2 (Interests: travel, food, fashion):\n",
            "--------------------------------------------------\n",
            "Test engagements to predict: 4 posts\n",
            "    1. Post P1 (Score: 0.700)\n",
            "     Type: video, Tags: sports, food\n",
            "    2. Post P5 (Score: 0.600)\n",
            "     Type: image, Tags: food, fashion\n",
            "    3. Post P80 (Score: 0.600)\n",
            "     Type: video, Tags: travel, food\n",
            "\n",
            "User U3 (Interests: sports, travel, fashion):\n",
            "--------------------------------------------------\n",
            "Test engagements to predict: 4 posts\n",
            "    1. Post P39 (Score: 0.890)\n",
            "     Type: video, Tags: travel, sports\n",
            "    2. Post P1 (Score: 0.674)\n",
            "     Type: video, Tags: sports, food\n",
            "    3. Post P34 (Score: 0.600)\n",
            "     Type: video, Tags: travel, sports\n",
            "\n",
            "User U4 (Interests: fashion, music, tech):\n",
            "--------------------------------------------------\n",
            "Test engagements to predict: 4 posts\n",
            "    1. Post P53 (Score: 1.000)\n",
            "     Type: video, Tags: fashion, tech\n",
            "  ✓ HIT! 2. Post P37 (Score: 0.765)\n",
            "     Type: text, Tags: tech, music\n",
            "    3. Post P96 (Score: 0.600)\n",
            "     Type: video, Tags: music, fashion\n",
            "\n",
            "User U5 (Interests: fashion, food, fitness):\n",
            "--------------------------------------------------\n",
            "Test engagements to predict: 4 posts\n",
            "    1. Post P5 (Score: 0.600)\n",
            "     Type: image, Tags: food, fashion\n",
            "    2. Post P7 (Score: 0.600)\n",
            "     Type: image, Tags: food, fitness\n",
            "    3. Post P26 (Score: 0.600)\n",
            "     Type: image, Tags: food, fitness\n",
            "\n",
            "User U6 (Interests: fashion, food, fitness):\n",
            "--------------------------------------------------\n",
            "Test engagements to predict: 4 posts\n",
            "    1. Post P7 (Score: 0.600)\n",
            "     Type: image, Tags: food, fitness\n",
            "    2. Post P26 (Score: 0.600)\n",
            "     Type: image, Tags: food, fitness\n",
            "    3. Post P35 (Score: 0.600)\n",
            "     Type: image, Tags: fitness, food\n",
            "\n",
            "User U7 (Interests: food, fashion, art):\n",
            "--------------------------------------------------\n",
            "Test engagements to predict: 4 posts\n",
            "    1. Post P70 (Score: 0.957)\n",
            "     Type: image, Tags: art, food\n",
            "    2. Post P69 (Score: 0.945)\n",
            "     Type: text, Tags: fashion, food\n",
            "    3. Post P5 (Score: 0.600)\n",
            "     Type: image, Tags: food, fashion\n",
            "\n",
            "User U8 (Interests: food, sports, gaming):\n",
            "--------------------------------------------------\n",
            "Test engagements to predict: 4 posts\n",
            "    1. Post P1 (Score: 0.600)\n",
            "     Type: video, Tags: sports, food\n",
            "    2. Post P17 (Score: 0.600)\n",
            "     Type: video, Tags: food, sports\n",
            "    3. Post P46 (Score: 0.600)\n",
            "     Type: video, Tags: food, sports\n",
            "\n",
            "User U9 (Interests: art, travel, sports):\n",
            "--------------------------------------------------\n",
            "Test engagements to predict: 4 posts\n",
            "    1. Post P34 (Score: 0.600)\n",
            "     Type: video, Tags: travel, sports\n",
            "    2. Post P78 (Score: 0.600)\n",
            "     Type: video, Tags: sports, art\n",
            "    3. Post P97 (Score: 0.600)\n",
            "     Type: video, Tags: travel, sports\n",
            "\n",
            "User U10 (Interests: fashion, music, literature):\n",
            "--------------------------------------------------\n",
            "Test engagements to predict: 4 posts\n",
            "    1. Post P14 (Score: 0.756)\n",
            "     Type: text, Tags: literature, music\n",
            "    2. Post P54 (Score: 0.600)\n",
            "     Type: video, Tags: literature, music\n",
            "    3. Post P57 (Score: 0.400)\n",
            "     Type: text, Tags: sports, literature\n",
            "\n",
            "============================================================\n",
            "EVALUATION RESULTS (TEST DATA)\n",
            "============================================================\n",
            "Precision@3: 0.0333\n",
            "User Coverage@3: 0.1000\n",
            "Total Recommendations: 150\n",
            "Total Hits: 5\n",
            "Users with at least one hit: 5/50\n",
            "\n",
            "Saving recommendations to recommendations.csv...\n",
            "Successfully saved 50 user recommendations to recommendations.csv\n",
            "Successfully saved detailed recommendations to detailed_recommendations.csv\n",
            "\n",
            "============================================================\n",
            "METHOD COMPARISON\n",
            "============================================================\n",
            "Precision@3: 0.0400\n",
            "User Coverage@3: 0.1200\n",
            "Total Recommendations: 150\n",
            "Total Hits: 6\n",
            "Users with at least one hit: 6/50\n",
            "Content-Based        Precision@3: 0.0400, Coverage: 0.1200\n",
            "Precision@3: 0.0733\n",
            "User Coverage@3: 0.2200\n",
            "Total Recommendations: 150\n",
            "Total Hits: 11\n",
            "Users with at least one hit: 11/50\n",
            "Collaborative        Precision@3: 0.0733, Coverage: 0.2200\n",
            "Precision@3: 0.0333\n",
            "User Coverage@3: 0.1000\n",
            "Total Recommendations: 150\n",
            "Total Hits: 5\n",
            "Users with at least one hit: 5/50\n",
            "Hybrid               Precision@3: 0.0333, Coverage: 0.1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fLyD06-JvWMU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}